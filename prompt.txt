Revise the preprocessing steps, prepare the data with techniques and methodologies from suitable for the dataset, encompassing the steps used in the Spaceship titanic 4 notebook's context such as columns transformations, principal component analysis and a pipeline for suitable encoders and scalers while following these as guidelines - Standardization/Normalization (Apply appropriate scaling techniques to standardize or normalize numerical features), Feature Encoding (Transform categorical features using the appropriate techniques (e.g. One-hot encoding, Label encoding etc.)). Feature Selection (Select relevant features that contribute most to predicting the target variable and exclude those that donâ€™t)
Using the context and technique from the Spaceship Titanic notebook, analyze it to detect the pattern of decisions taken for training the model and choosing the model as well as metricsChoose at least four different machine learning models suitable for your this dataset. Justify your choice of models based on their suitability for the problem at hand (e.g. handling non-linearity) using markdown cells. Train each model using appropriate techniques (e.g. cross-validation) and evaluate their performance using relevant metrics (accuracy, F1-score, RMSE, etc.). Utilize the Seaborn library to create meaningful visualizations that support your analysis (e.g. confusion matrices, ROC curves, etc.).